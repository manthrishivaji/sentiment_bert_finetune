{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:17.631857Z","iopub.execute_input":"2025-01-31T03:14:17.632108Z","iopub.status.idle":"2025-01-31T03:14:18.963377Z","shell.execute_reply.started":"2025-01-31T03:14:17.632085Z","shell.execute_reply":"2025-01-31T03:14:18.962474Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n                AutoTokenizer,\n                AutoModelForCausalLM,\n                Trainer,\n                TrainingArguments,\n                DataCollatorForLanguageModeling\n                )\nfrom torchinfo import summary\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:18.964473Z","iopub.execute_input":"2025-01-31T03:14:18.965003Z","iopub.status.idle":"2025-01-31T03:14:41.031380Z","shell.execute_reply.started":"2025-01-31T03:14:18.964968Z","shell.execute_reply":"2025-01-31T03:14:41.030707Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!kaggle datasets download -d abhi8923shriv/sentiment-analysis-dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:41.032627Z","iopub.execute_input":"2025-01-31T03:14:41.033222Z","iopub.status.idle":"2025-01-31T03:14:42.728626Z","shell.execute_reply.started":"2025-01-31T03:14:41.033183Z","shell.execute_reply":"2025-01-31T03:14:42.727547Z"}},"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset\nLicense(s): CC0-1.0\nDownloading sentiment-analysis-dataset.zip to /kaggle/working\n 94%|████████████████████████████████████▌  | 51.0M/54.4M [00:00<00:00, 115MB/s]\n100%|███████████████████████████████████████| 54.4M/54.4M [00:00<00:00, 132MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from zipfile import ZipFile\n\nzip_file_name = '/kaggle/working/sentiment-analysis-dataset.zip'\n\nwith ZipFile(zip_file_name, 'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working/data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:42.730256Z","iopub.execute_input":"2025-01-31T03:14:42.730494Z","iopub.status.idle":"2025-01-31T03:14:43.736032Z","shell.execute_reply.started":"2025-01-31T03:14:42.730472Z","shell.execute_reply":"2025-01-31T03:14:43.735322Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_train =  pd.read_csv('/kaggle/working/data/train.csv',encoding='ISO-8859-1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.736928Z","iopub.execute_input":"2025-01-31T03:14:43.737237Z","iopub.status.idle":"2025-01-31T03:14:43.846258Z","shell.execute_reply.started":"2025-01-31T03:14:43.737206Z","shell.execute_reply":"2025-01-31T03:14:43.845556Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data_train.head(4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.847143Z","iopub.execute_input":"2025-01-31T03:14:43.847447Z","iopub.status.idle":"2025-01-31T03:14:43.900433Z","shell.execute_reply.started":"2025-01-31T03:14:43.847415Z","shell.execute_reply":"2025-01-31T03:14:43.899687Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       textID                                            text  \\\n0  cb774db0d1             I`d have responded, if I were going   \n1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                       my boss is bullying me...   \n3  9642c003ef                  what interview! leave me alone   \n\n                         selected_text sentiment Time of Tweet Age of User  \\\n0  I`d have responded, if I were going   neutral       morning        0-20   \n1                             Sooo SAD  negative          noon       21-30   \n2                          bullying me  negative         night       31-45   \n3                       leave me alone  negative       morning       46-60   \n\n       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n0  Afghanistan          38928346         652860.0               60  \n1      Albania           2877797          27400.0              105  \n2      Algeria          43851044        2381740.0               18  \n3      Andorra             77265            470.0              164  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# I want to clean the text to proceed further :\n# And i want only text and sentiment column , i am gonna select those two.\n\n# data_train_selected = data_train.drop(columns=['textID', 'text', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'], axis=1)\n\n# data_train_selected = data_train.loc[:, [ 'selected_text', 'sentiment']]\n\ndata_train_selected = data_train.filter(items=['selected_text', 'sentiment'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.901249Z","iopub.execute_input":"2025-01-31T03:14:43.901550Z","iopub.status.idle":"2025-01-31T03:14:43.911296Z","shell.execute_reply.started":"2025-01-31T03:14:43.901517Z","shell.execute_reply":"2025-01-31T03:14:43.910464Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data_train_selected.head(4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.914078Z","iopub.execute_input":"2025-01-31T03:14:43.914326Z","iopub.status.idle":"2025-01-31T03:14:43.921455Z","shell.execute_reply.started":"2025-01-31T03:14:43.914305Z","shell.execute_reply":"2025-01-31T03:14:43.920807Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                         selected_text sentiment\n0  I`d have responded, if I were going   neutral\n1                             Sooo SAD  negative\n2                          bullying me  negative\n3                       leave me alone  negative","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data_train_selected['selected_text'] = data_train_selected['selected_text'].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.923005Z","iopub.execute_input":"2025-01-31T03:14:43.923275Z","iopub.status.idle":"2025-01-31T03:14:43.933139Z","shell.execute_reply.started":"2025-01-31T03:14:43.923255Z","shell.execute_reply":"2025-01-31T03:14:43.932329Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def clean_text(text):\n    # Remove URLs and HTML tags\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n    text = re.sub(r'<.*?>', '', text)\n    \n    # Remove punctuation and special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Lowercase the text\n    text = text.lower()\n    \n    return text\n\ndata_train_selected['cleaned_text'] = data_train_selected['selected_text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:43.934170Z","iopub.execute_input":"2025-01-31T03:14:43.934445Z","iopub.status.idle":"2025-01-31T03:14:44.042369Z","shell.execute_reply.started":"2025-01-31T03:14:43.934425Z","shell.execute_reply":"2025-01-31T03:14:44.041587Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data_train_selected.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:44.043211Z","iopub.execute_input":"2025-01-31T03:14:44.043485Z","iopub.status.idle":"2025-01-31T03:14:44.051227Z","shell.execute_reply.started":"2025-01-31T03:14:44.043456Z","shell.execute_reply":"2025-01-31T03:14:44.050596Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                         selected_text sentiment  \\\n0  I`d have responded, if I were going   neutral   \n1                             Sooo SAD  negative   \n2                          bullying me  negative   \n3                       leave me alone  negative   \n4                        Sons of ****,  negative   \n\n                        cleaned_text  \n0  id have responded if i were going  \n1                           sooo sad  \n2                        bullying me  \n3                     leave me alone  \n4                           sons of   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>id have responded if i were going</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>sooo sad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>bullying me</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>leave me alone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>sons of</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"data_train_selected['sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:44.051975Z","iopub.execute_input":"2025-01-31T03:14:44.052203Z","iopub.status.idle":"2025-01-31T03:14:44.069960Z","shell.execute_reply.started":"2025-01-31T03:14:44.052183Z","shell.execute_reply":"2025-01-31T03:14:44.069197Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"sentiment\nneutral     11118\npositive     8582\nnegative     7781\nName: count, dtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Configuration\n\nmodel_name = 'google-bert/bert-base-uncased'\noutput_dir = '/kaggle/working/fine_tuned_model'\nmax_length = 512\nbatch_size = 8\nlearning_rate = 1e-4\n# epochs = 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:44.070824Z","iopub.execute_input":"2025-01-31T03:14:44.071142Z","iopub.status.idle":"2025-01-31T03:14:44.081622Z","shell.execute_reply.started":"2025-01-31T03:14:44.071119Z","shell.execute_reply":"2025-01-31T03:14:44.080678Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n# Load model and tokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Change num_labels as needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:44.082573Z","iopub.execute_input":"2025-01-31T03:14:44.082890Z","iopub.status.idle":"2025-01-31T03:14:47.956694Z","shell.execute_reply.started":"2025-01-31T03:14:44.082859Z","shell.execute_reply":"2025-01-31T03:14:47.955890Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e6c490bbbee43218433461d70a2ca66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08f5573810154ec3ad1ad4facd2f605a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5d275afd50482ea5545e96a90b2a57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2b097037c643f6b17e676068393501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeced6612666495c9421465bfa9750f0"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:47.957663Z","iopub.execute_input":"2025-01-31T03:14:47.957991Z","iopub.status.idle":"2025-01-31T03:14:47.964037Z","shell.execute_reply.started":"2025-01-31T03:14:47.957957Z","shell.execute_reply":"2025-01-31T03:14:47.963234Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:47.964835Z","iopub.execute_input":"2025-01-31T03:14:47.965117Z","iopub.status.idle":"2025-01-31T03:14:48.032341Z","shell.execute_reply.started":"2025-01-31T03:14:47.965087Z","shell.execute_reply":"2025-01-31T03:14:48.031512Z"}},"outputs":[{"name":"stdout","text":"Total parameters: 109484547\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Trainable parameters:\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Trainable parameters: {trainable_params}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.033072Z","iopub.execute_input":"2025-01-31T03:14:48.033314Z","iopub.status.idle":"2025-01-31T03:14:48.044411Z","shell.execute_reply.started":"2025-01-31T03:14:48.033294Z","shell.execute_reply":"2025-01-31T03:14:48.043832Z"}},"outputs":[{"name":"stdout","text":"Trainable parameters: 109484547\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"summary(model)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.045264Z","iopub.execute_input":"2025-01-31T03:14:48.045490Z","iopub.status.idle":"2025-01-31T03:14:48.148591Z","shell.execute_reply.started":"2025-01-31T03:14:48.045471Z","shell.execute_reply":"2025-01-31T03:14:48.147764Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"=====================================================================================\nLayer (type:depth-idx)                                       Param #\n=====================================================================================\nBertForSequenceClassification                                --\n├─BertModel: 1-1                                             --\n│    └─BertEmbeddings: 2-1                                   --\n│    │    └─Embedding: 3-1                                   23,440,896\n│    │    └─Embedding: 3-2                                   393,216\n│    │    └─Embedding: 3-3                                   1,536\n│    │    └─LayerNorm: 3-4                                   1,536\n│    │    └─Dropout: 3-5                                     --\n│    └─BertEncoder: 2-2                                      --\n│    │    └─ModuleList: 3-6                                  85,054,464\n│    └─BertPooler: 2-3                                       --\n│    │    └─Linear: 3-7                                      590,592\n│    │    └─Tanh: 3-8                                        --\n├─Dropout: 1-2                                               --\n├─Linear: 1-3                                                2,307\n=====================================================================================\nTotal params: 109,484,547\nTrainable params: 109,484,547\nNon-trainable params: 0\n====================================================================================="},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for param in model.bert.embeddings.parameters():\n#     param.requires_grad = False\n\n# # Trainable parameters:\n# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# print(f'Trainable parameters: {trainable_params}')\n\n# for layer in model.bert.encoder.layer[:6]:  # Freeze layers 0 to 5\n#     for param in layer.parameters():\n#         param.requires_grad = False\n\n# # Trainable parameters:\n# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# print(f'Trainable parameters: {trainable_params}')\n\n# # Freeze the entire BERT Model(Except the Head)\n# for param in model.bert.parameters():\n#     param.requires_grad = False\n# # Trainable parameters:\n# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n# print(f'Trainable parameters: {trainable_params}')\n\n# # Unfreeze the classification Head:\n# for param in model.cls.parameters():\n#     param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.149595Z","iopub.execute_input":"2025-01-31T03:14:48.149954Z","iopub.status.idle":"2025-01-31T03:14:48.156870Z","shell.execute_reply.started":"2025-01-31T03:14:48.149919Z","shell.execute_reply":"2025-01-31T03:14:48.156158Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# # Detailed parameter breakdown:\n# for name, param in model.named_parameters():\n#     print(f\"{name}: {param.numel()} parameters (Trainable: {param.requires_grad})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.157728Z","iopub.execute_input":"2025-01-31T03:14:48.158007Z","iopub.status.idle":"2025-01-31T03:14:48.168312Z","shell.execute_reply.started":"2025-01-31T03:14:48.157987Z","shell.execute_reply":"2025-01-31T03:14:48.167526Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#Freeze the entire BERT Model(Except the Head)\nfor param in model.bert.parameters():\n    param.requires_grad = True\n# Trainable parameters:\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Trainable parameters: {trainable_params}')\n\n#Unfreeze the classification Head:\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Trainable parameters:\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Trainable parameters: {trainable_params}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.169057Z","iopub.execute_input":"2025-01-31T03:14:48.169310Z","iopub.status.idle":"2025-01-31T03:14:48.178654Z","shell.execute_reply.started":"2025-01-31T03:14:48.169290Z","shell.execute_reply":"2025-01-31T03:14:48.177831Z"}},"outputs":[{"name":"stdout","text":"Trainable parameters: 109484547\nTrainable parameters: 109484547\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"data_test = pd.read_csv('/kaggle/working/data/test.csv',encoding='ISO-8859-1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.179532Z","iopub.execute_input":"2025-01-31T03:14:48.179833Z","iopub.status.idle":"2025-01-31T03:14:48.205256Z","shell.execute_reply.started":"2025-01-31T03:14:48.179795Z","shell.execute_reply":"2025-01-31T03:14:48.204463Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.209019Z","iopub.execute_input":"2025-01-31T03:14:48.209244Z","iopub.status.idle":"2025-01-31T03:14:48.225796Z","shell.execute_reply.started":"2025-01-31T03:14:48.209224Z","shell.execute_reply":"2025-01-31T03:14:48.225027Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          textID                                               text sentiment  \\\n0     f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n1     96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n2     eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n3     01082688c6                                        happy bday!  positive   \n4     33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n...          ...                                                ...       ...   \n4810         NaN                                                NaN       NaN   \n4811         NaN                                                NaN       NaN   \n4812         NaN                                                NaN       NaN   \n4813         NaN                                                NaN       NaN   \n4814         NaN                                                NaN       NaN   \n\n     Time of Tweet Age of User      Country  Population -2020  \\\n0          morning        0-20  Afghanistan        38928346.0   \n1             noon       21-30      Albania         2877797.0   \n2            night       31-45      Algeria        43851044.0   \n3          morning       46-60      Andorra           77265.0   \n4             noon       60-70       Angola        32866272.0   \n...            ...         ...          ...               ...   \n4810           NaN         NaN          NaN               NaN   \n4811           NaN         NaN          NaN               NaN   \n4812           NaN         NaN          NaN               NaN   \n4813           NaN         NaN          NaN               NaN   \n4814           NaN         NaN          NaN               NaN   \n\n      Land Area (Km²)  Density (P/Km²)  \n0            652860.0             60.0  \n1             27400.0            105.0  \n2           2381740.0             18.0  \n3               470.0            164.0  \n4           1246700.0             26.0  \n...               ...              ...  \n4810              NaN              NaN  \n4811              NaN              NaN  \n4812              NaN              NaN  \n4813              NaN              NaN  \n4814              NaN              NaN  \n\n[4815 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346.0</td>\n      <td>652860.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>Shanghai is also really exciting (precisely -...</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797.0</td>\n      <td>27400.0</td>\n      <td>105.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>Recession hit Veronique Branquinho, she has to...</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044.0</td>\n      <td>2381740.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n      <td>positive</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265.0</td>\n      <td>470.0</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272.0</td>\n      <td>1246700.0</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4810</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4811</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4812</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4813</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4814</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4815 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"data_test_selected = data_test.filter(items=['text', 'sentiment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.227064Z","iopub.execute_input":"2025-01-31T03:14:48.227248Z","iopub.status.idle":"2025-01-31T03:14:48.231688Z","shell.execute_reply.started":"2025-01-31T03:14:48.227231Z","shell.execute_reply":"2025-01-31T03:14:48.230788Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"data_test_selected['sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.232502Z","iopub.execute_input":"2025-01-31T03:14:48.232715Z","iopub.status.idle":"2025-01-31T03:14:48.244718Z","shell.execute_reply.started":"2025-01-31T03:14:48.232685Z","shell.execute_reply":"2025-01-31T03:14:48.243984Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"sentiment\nneutral     1430\npositive    1103\nnegative    1001\nName: count, dtype: int64"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"data_test_selected.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.245643Z","iopub.execute_input":"2025-01-31T03:14:48.245959Z","iopub.status.idle":"2025-01-31T03:14:48.264800Z","shell.execute_reply.started":"2025-01-31T03:14:48.245936Z","shell.execute_reply":"2025-01-31T03:14:48.263956Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4815 entries, 0 to 4814\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   text       3534 non-null   object\n 1   sentiment  3534 non-null   object\ndtypes: object(2)\nmemory usage: 75.4+ KB\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"data_test_selected.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.265771Z","iopub.execute_input":"2025-01-31T03:14:48.265974Z","iopub.status.idle":"2025-01-31T03:14:48.277498Z","shell.execute_reply.started":"2025-01-31T03:14:48.265956Z","shell.execute_reply":"2025-01-31T03:14:48.276680Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"data_test_selected['text'] = data_test_selected['text'].astype(str)\n\ndef clean_text(text):\n    # Remove URLs and HTML tags\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n    text = re.sub(r'<.*?>', '', text)\n    \n    # Remove punctuation and special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Lowercase the text\n    text = text.lower()\n    \n    return text\n\ndata_test_selected['cleaned_text'] = data_test_selected['text'].apply(clean_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.278584Z","iopub.execute_input":"2025-01-31T03:14:48.279022Z","iopub.status.idle":"2025-01-31T03:14:48.307657Z","shell.execute_reply.started":"2025-01-31T03:14:48.278989Z","shell.execute_reply":"2025-01-31T03:14:48.306969Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"data_test_selected","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.308588Z","iopub.execute_input":"2025-01-31T03:14:48.308900Z","iopub.status.idle":"2025-01-31T03:14:48.324745Z","shell.execute_reply.started":"2025-01-31T03:14:48.308877Z","shell.execute_reply":"2025-01-31T03:14:48.324051Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                                   text sentiment  \\\n0     Last session of the day  http://twitpic.com/67ezh   neutral   \n1      Shanghai is also really exciting (precisely -...  positive   \n2     Recession hit Veronique Branquinho, she has to...  negative   \n3                                           happy bday!  positive   \n4                http://twitpic.com/4w75p - I like it!!  positive   \n...                                                 ...       ...   \n3529  its at 3 am, im very tired but i can`t sleep  ...  negative   \n3530  All alone in this old house again.  Thanks for...  positive   \n3531   I know what you mean. My little dog is sinkin...  negative   \n3532  _sutra what is your next youtube video gonna b...  positive   \n3533   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive   \n\n                                           cleaned_text  \n0                             last session of the day    \n1      shanghai is also really exciting precisely  s...  \n2     recession hit veronique branquinho she has to ...  \n3                                            happy bday  \n4                                             i like it  \n...                                                 ...  \n3529  its at 3 am im very tired but i cant sleep  bu...  \n3530  all alone in this old house again  thanks for ...  \n3531   i know what you mean my little dog is sinking...  \n3532  _sutra what is your next youtube video gonna b...  \n3533                            omgssh  ang cute ng bby  \n\n[3534 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n      <td>last session of the day</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Shanghai is also really exciting (precisely -...</td>\n      <td>positive</td>\n      <td>shanghai is also really exciting precisely  s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Recession hit Veronique Branquinho, she has to...</td>\n      <td>negative</td>\n      <td>recession hit veronique branquinho she has to ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday!</td>\n      <td>positive</td>\n      <td>happy bday</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n      <td>i like it</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3529</th>\n      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n      <td>negative</td>\n      <td>its at 3 am im very tired but i cant sleep  bu...</td>\n    </tr>\n    <tr>\n      <th>3530</th>\n      <td>All alone in this old house again.  Thanks for...</td>\n      <td>positive</td>\n      <td>all alone in this old house again  thanks for ...</td>\n    </tr>\n    <tr>\n      <th>3531</th>\n      <td>I know what you mean. My little dog is sinkin...</td>\n      <td>negative</td>\n      <td>i know what you mean my little dog is sinking...</td>\n    </tr>\n    <tr>\n      <th>3532</th>\n      <td>_sutra what is your next youtube video gonna b...</td>\n      <td>positive</td>\n      <td>_sutra what is your next youtube video gonna b...</td>\n    </tr>\n    <tr>\n      <th>3533</th>\n      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n      <td>positive</td>\n      <td>omgssh  ang cute ng bby</td>\n    </tr>\n  </tbody>\n</table>\n<p>3534 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"test_texts = data_test_selected['cleaned_text'].tolist()\ntest_labels = data_test_selected['sentiment'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.325481Z","iopub.execute_input":"2025-01-31T03:14:48.325789Z","iopub.status.idle":"2025-01-31T03:14:48.336775Z","shell.execute_reply.started":"2025-01-31T03:14:48.325740Z","shell.execute_reply":"2025-01-31T03:14:48.335956Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\ntest_labels_encoded = label_encoder.fit_transform(test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.337487Z","iopub.execute_input":"2025-01-31T03:14:48.337743Z","iopub.status.idle":"2025-01-31T03:14:48.351047Z","shell.execute_reply.started":"2025-01-31T03:14:48.337722Z","shell.execute_reply":"2025-01-31T03:14:48.349973Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Prepare the Dataset Class:\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = tokenizer(\n                             self.texts[idx],\n                             truncation=True, \n                             padding='max_length',\n                             max_length=128\n                            )\n        # Convert everything to tensors\n        item = {key: torch.tensor(val) for key, val in encoding.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n        # return {**encoding, 'labels':self.labels[idx]}\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.351804Z","iopub.execute_input":"2025-01-31T03:14:48.352076Z","iopub.status.idle":"2025-01-31T03:14:48.362575Z","shell.execute_reply.started":"2025-01-31T03:14:48.352049Z","shell.execute_reply":"2025-01-31T03:14:48.361851Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"test_dataset = SentimentDataset(test_texts, test_labels_encoded)\ntest_loader = DataLoader(test_dataset, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.363464Z","iopub.execute_input":"2025-01-31T03:14:48.363741Z","iopub.status.idle":"2025-01-31T03:14:48.378000Z","shell.execute_reply.started":"2025-01-31T03:14:48.363713Z","shell.execute_reply":"2025-01-31T03:14:48.377209Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"train_texts = data_train_selected['cleaned_text'].tolist()\ntrain_labels = data_train_selected['sentiment'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.378862Z","iopub.execute_input":"2025-01-31T03:14:48.379168Z","iopub.status.idle":"2025-01-31T03:14:48.391027Z","shell.execute_reply.started":"2025-01-31T03:14:48.379139Z","shell.execute_reply":"2025-01-31T03:14:48.390241Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\ntrain_labels_encoded = label_encoder.fit_transform(train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.391877Z","iopub.execute_input":"2025-01-31T03:14:48.392117Z","iopub.status.idle":"2025-01-31T03:14:48.412596Z","shell.execute_reply.started":"2025-01-31T03:14:48.392088Z","shell.execute_reply":"2025-01-31T03:14:48.411732Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_dataset = SentimentDataset(train_texts, train_labels_encoded)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.413362Z","iopub.execute_input":"2025-01-31T03:14:48.413593Z","iopub.status.idle":"2025-01-31T03:14:48.417407Z","shell.execute_reply.started":"2025-01-31T03:14:48.413564Z","shell.execute_reply":"2025-01-31T03:14:48.416600Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Check if GPU is available and set device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)  # Move model to the appropriate device\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.418095Z","iopub.execute_input":"2025-01-31T03:14:48.418318Z","iopub.status.idle":"2025-01-31T03:14:48.799040Z","shell.execute_reply.started":"2025-01-31T03:14:48.418300Z","shell.execute_reply":"2025-01-31T03:14:48.798318Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## Lets test pretrained model on test data, ad evaluate the scores","metadata":{}},{"cell_type":"code","source":"# model.eval()\n# predictions, true_labels = [], []\n\n# with torch.no_grad():\n#     for batch in test_loader:\n#         # Move batch to the appropriate device\n#         for key in batch.keys():\n#             batch[key] = batch[key].to(device)\n\n#         outputs = model(**batch)\n#         logits = outputs.logits\n#         preds = torch.argmax(logits, dim=-1)\n#         predictions.extend(preds.cpu().numpy())  # Move predictions back to CPU for metric calculation\n#         true_labels.extend(batch['labels'].cpu().numpy())  # Move true labels back to CPU\n\n# # Calculate accuracy and other metrics\n# accuracy = accuracy_score(true_labels, predictions)\n# report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n\n# print(f\"Accuracy: {accuracy}\")\n# print(report)\n\nfrom tqdm import tqdm  # Import tqdm for progress bar\nimport torch\nfrom sklearn.metrics import accuracy_score, classification_report\n\nmodel.eval()\npredictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n        # Move batch to the appropriate device\n        for key in batch.keys():\n            batch[key] = batch[key].to(device)\n\n        outputs = model(**batch)\n        \n        logits = outputs.logits\n        \n        preds = torch.argmax(logits, dim=-1)\n        \n        predictions.extend(preds.cpu().numpy())  # Move predictions back to CPU for metric calculation\n        true_labels.extend(batch['labels'].cpu().numpy())  # Move true labels back to CPU\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(true_labels, predictions)\nreport = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:14:48.799782Z","iopub.execute_input":"2025-01-31T03:14:48.800068Z","iopub.status.idle":"2025-01-31T03:15:13.824471Z","shell.execute_reply.started":"2025-01-31T03:14:48.800046Z","shell.execute_reply":"2025-01-31T03:15:13.823561Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 221/221 [00:24<00:00,  8.84batch/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.4046\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1001\n     neutral       0.40      1.00      0.58      1430\n    positive       0.00      0.00      0.00      1103\n\n    accuracy                           0.40      3534\n   macro avg       0.13      0.33      0.19      3534\nweighted avg       0.16      0.40      0.23      3534\n\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## So the bert model shows poor performance on the test data, so lets the fine tune it , and check the models performance","metadata":{}},{"cell_type":"code","source":"# Configuration\n\nmodel_name = 'google-bert/bert-base-uncased'\noutput_dir = '/kaggle/working/fine_tuned_model'\nmax_length = 128\nbatch_size = 8\nlearning_rate = 1e-4\nepochs = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:15:13.825523Z","iopub.execute_input":"2025-01-31T03:15:13.825895Z","iopub.status.idle":"2025-01-31T03:15:13.830680Z","shell.execute_reply.started":"2025-01-31T03:15:13.825867Z","shell.execute_reply":"2025-01-31T03:15:13.829734Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    evaluation_strategy=\"epoch\",\n    learning_rate=learning_rate,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    save_total_limit=2,\n    report_to=\"tensorboard\",\n    fp16=torch.cuda.is_available(),\n    load_best_model_at_end=True\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    # data_collator=data_collator\n\n)\n\n# # To resume from the latest checkpoint\n# trainer.train(resume_from_checkpoint=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:15:13.831600Z","iopub.execute_input":"2025-01-31T03:15:13.831910Z","iopub.status.idle":"2025-01-31T03:15:14.065915Z","shell.execute_reply.started":"2025-01-31T03:15:13.831887Z","shell.execute_reply":"2025-01-31T03:15:14.065288Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-40-9077b6e77ed1>:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Train the model\ntrainer.train()\n\n# Evaluate the model on the test dataset after training\neval_results = trainer.evaluate()\nprint(eval_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:15:14.066594Z","iopub.execute_input":"2025-01-31T03:15:14.066899Z","iopub.status.idle":"2025-01-31T04:48:01.391780Z","shell.execute_reply.started":"2025-01-31T03:15:14.066866Z","shell.execute_reply":"2025-01-31T04:48:01.390927Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17180' max='17180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17180/17180 1:32:23, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.415800</td>\n      <td>0.987391</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.304200</td>\n      <td>1.122791</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.303200</td>\n      <td>1.189343</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.309800</td>\n      <td>2.594054</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.553700</td>\n      <td>5.190302</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.567400</td>\n      <td>5.769426</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.393000</td>\n      <td>5.713596</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.486700</td>\n      <td>5.751124</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.259800</td>\n      <td>6.327115</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.254200</td>\n      <td>5.986694</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='221' max='221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [221/221 00:21]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.9873910546302795, 'eval_runtime': 21.5298, 'eval_samples_per_second': 164.144, 'eval_steps_per_second': 10.265, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from tqdm import tqdm  # Import tqdm for progress bar\nimport torch\nfrom sklearn.metrics import accuracy_score, classification_report\n\nmodel.eval()\npredictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n        # Move batch to the appropriate device\n        for key in batch.keys():\n            batch[key] = batch[key].to(device)\n\n        outputs = model(**batch)\n        \n        logits = outputs.logits\n        \n        preds = torch.argmax(logits, dim=-1)\n        \n        predictions.extend(preds.cpu().numpy())  # Move predictions back to CPU for metric calculation\n        true_labels.extend(batch['labels'].cpu().numpy())  # Move true labels back to CPU\n\n# Calculate accuracy and other metrics\naccuracy = accuracy_score(true_labels, predictions)\nreport = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:01.392717Z","iopub.execute_input":"2025-01-31T04:48:01.393061Z","iopub.status.idle":"2025-01-31T04:48:31.191459Z","shell.execute_reply.started":"2025-01-31T04:48:01.393025Z","shell.execute_reply":"2025-01-31T04:48:31.190598Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 221/221 [00:29<00:00,  7.42batch/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6095\n              precision    recall  f1-score   support\n\n    negative       0.82      0.29      0.42      1001\n     neutral       0.51      0.89      0.65      1430\n    positive       0.85      0.54      0.66      1103\n\n    accuracy                           0.61      3534\n   macro avg       0.73      0.57      0.58      3534\nweighted avg       0.70      0.61      0.59      3534\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Save the trained model\ntrainer.save_model()  # This saves the model to output_dir specified in TrainingArguments\n\n# Save the tokenizer\ntokenizer.save_pretrained(training_args.output_dir)  # This saves the tokenizer to the same directory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:31.192339Z","iopub.execute_input":"2025-01-31T04:48:31.192607Z","iopub.status.idle":"2025-01-31T04:48:32.249124Z","shell.execute_reply.started":"2025-01-31T04:48:31.192573Z","shell.execute_reply":"2025-01-31T04:48:32.248111Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine_tuned_model/tokenizer_config.json',\n '/kaggle/working/fine_tuned_model/special_tokens_map.json',\n '/kaggle/working/fine_tuned_model/vocab.txt',\n '/kaggle/working/fine_tuned_model/added_tokens.json',\n '/kaggle/working/fine_tuned_model/tokenizer.json')"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Define the path where the model is saved\nmodel_path = \"/kaggle/working/fine_tuned_model\"\n\n# Load the tokenizer\ntokenizer_finetuned = AutoTokenizer.from_pretrained(model_path)\n\n# Load the model\nmodel_finetuned = AutoModelForSequenceClassification.from_pretrained(model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:32.250276Z","iopub.execute_input":"2025-01-31T04:48:32.250601Z","iopub.status.idle":"2025-01-31T04:48:32.349555Z","shell.execute_reply.started":"2025-01-31T04:48:32.250569Z","shell.execute_reply":"2025-01-31T04:48:32.348688Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## Evaluate test data by loading the saved finetuned model","metadata":{}},{"cell_type":"code","source":"# # Check if GPU is available and set device accordingly\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model_finetuned.to(device)  # Move model to the appropriate device\n# print(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:32.350581Z","iopub.execute_input":"2025-01-31T04:48:32.350920Z","iopub.status.idle":"2025-01-31T04:48:32.514933Z","shell.execute_reply.started":"2025-01-31T04:48:32.350887Z","shell.execute_reply":"2025-01-31T04:48:32.514053Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# # Prepare the Dataset Class:\n# class SentimentDataset(Dataset):\n#     def __init__(self, texts, labels):\n#         self.texts = texts\n#         self.labels = labels\n\n#     def __len__(self):\n#         return len(self.texts)\n\n#     def __getitem__(self, idx):\n#         encoding = tokenizer_finetuned(\n#                              self.texts[idx],\n#                              truncation=True, \n#                              padding='max_length',\n#                              max_length=128\n#                             )\n#         # Convert everything to tensors\n#         item = {key: torch.tensor(val) for key, val in encoding.items()}\n#         item['labels'] = torch.tensor(self.labels[idx])\n#         return item\n#         # return {**encoding, 'labels':self.labels[idx]}\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:32.515695Z","iopub.execute_input":"2025-01-31T04:48:32.515950Z","iopub.status.idle":"2025-01-31T04:48:32.521434Z","shell.execute_reply.started":"2025-01-31T04:48:32.515929Z","shell.execute_reply":"2025-01-31T04:48:32.520540Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# test_dataset_finetuned_tokenized = SentimentDataset(test_texts, test_labels_encoded)\n# test_loader_finetuned = DataLoader(test_dataset, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:32.522284Z","iopub.execute_input":"2025-01-31T04:48:32.522591Z","iopub.status.idle":"2025-01-31T04:48:32.534050Z","shell.execute_reply.started":"2025-01-31T04:48:32.522562Z","shell.execute_reply":"2025-01-31T04:48:32.533187Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# from tqdm import tqdm  # Import tqdm for progress bar\n# import torch\n# from sklearn.metrics import accuracy_score, classification_report\n\n# model_finetuned.eval()\n# predictions, true_labels = [], []\n\n# with torch.no_grad():\n#     for batch in tqdm(test_loader_finetuned, desc=\"Evaluating\", unit=\"batch\"):\n#         # Move batch to the appropriate device\n#         for key in batch.keys():\n#             batch[key] = batch[key].to(device)\n\n#         outputs = model_finetuned(**batch)\n        \n#         logits = outputs.logits\n        \n#         preds = torch.argmax(logits, dim=-1)\n        \n#         predictions.extend(preds.cpu().numpy())  # Move predictions back to CPU for metric calculation\n#         true_labels.extend(batch['labels'].cpu().numpy())  # Move true labels back to CPU\n\n# # Calculate accuracy and other metrics\n# accuracy = accuracy_score(true_labels, predictions)\n# report = classification_report(true_labels, predictions, target_names=label_encoder.classes_)\n\n# print(f\"Accuracy: {accuracy:.4f}\")\n# print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:48:32.535046Z","iopub.execute_input":"2025-01-31T04:48:32.535358Z","iopub.status.idle":"2025-01-31T04:49:02.062848Z","shell.execute_reply.started":"2025-01-31T04:48:32.535329Z","shell.execute_reply":"2025-01-31T04:49:02.062080Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 221/221 [00:29<00:00,  7.49batch/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6095\n              precision    recall  f1-score   support\n\n    negative       0.82      0.29      0.42      1001\n     neutral       0.51      0.89      0.65      1430\n    positive       0.85      0.54      0.66      1103\n\n    accuracy                           0.61      3534\n   macro avg       0.73      0.57      0.58      3534\nweighted avg       0.70      0.61      0.59      3534\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"### see we get same report as in test data on fine tuned model before training","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\nmodel.push_to_hub('Wolverine001/bert_finetuned_senti')\ntokenizer.push_to_hub('Wolverine001/bert_finetuned_senti')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:05:03.783384Z","iopub.execute_input":"2025-01-31T05:05:03.783658Z","iopub.status.idle":"2025-01-31T05:05:07.374496Z","shell.execute_reply.started":"2025-01-31T05:05:03.783638Z","shell.execute_reply":"2025-01-31T05:05:07.373820Z"}},"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Wolverine001/bert_finetuned_senti/commit/426ab4e593c12fbc1a976f8124401d176af8ab92', commit_message='Upload tokenizer', commit_description='', oid='426ab4e593c12fbc1a976f8124401d176af8ab92', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Wolverine001/bert_finetuned_senti', endpoint='https://huggingface.co', repo_type='model', repo_id='Wolverine001/bert_finetuned_senti'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"report_md = \"\"\"---\nlanguage: en\nlicense: mit\ndatasets: [twitter-sentiment]\nmetrics: [accuracy, f1, precision, recall]\n---\n\n# Fine-Tuned BERT Sentiment Model\n\nThis model was fine-tuned for sentiment classification.\n\n- Pre-trained model used:  google-bert/bert-base-uncased.\n- Dataset used:            twitter-sentiment.\n- max_length = 128\n- batch_size = 8\n- learning_rate = 1e-4\n- epochs = 3\n\n## **Evaluation Results**\n\n### 📌 **Before Fine-Tuning**\n**Accuracy:** 0.4046\n\n| Class      | Precision | Recall | F1-Score | Support |\n|------------|------------|------------|------------|------------|\n| Negative   | 0.00       | 0.00       | 0.00       | 1001 |\n| Neutral    | 0.40       | 1.00       | 0.58       | 1430 |\n| Positive   | 0.00       | 0.00       | 0.00       | 1103 |\n| **Macro Avg**  | 0.13   | 0.33       | 0.19       | 3534 |\n| **Weighted Avg**  | 0.16   | 0.40   | 0.23   | 3534 |\n\n---\n\n### ✅ **After Fine-Tuning**\n**Accuracy:** 0.6095\n\n| Class      | Precision | Recall | F1-Score | Support |\n|------------|------------|------------|------------|------------|\n| Negative   | 0.82       | 0.29       | 0.42       | 1001 |\n| Neutral    | 0.51       | 0.89       | 0.65       | 1430 |\n| Positive   | 0.85       | 0.54       | 0.66       | 1103 |\n| **Macro Avg**  | 0.73   | 0.57       | 0.58       | 3534 |\n| **Weighted Avg**  | 0.70   | 0.61   | 0.59   | 3534 |\n\n---\n\nYou can download the model from [Hugging Face](https://huggingface.co/Wolverine001/bert_finetuned_senti).\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:34:36.154346Z","iopub.execute_input":"2025-01-31T05:34:36.154644Z","iopub.status.idle":"2025-01-31T05:34:36.158716Z","shell.execute_reply.started":"2025-01-31T05:34:36.154623Z","shell.execute_reply":"2025-01-31T05:34:36.157843Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\n# Push the Markdown content to README.md\napi.upload_file(\n    path_or_fileobj=report_md.encode(),  # Convert string to bytes\n    path_in_repo=\"README.md\",  # Hugging Face uses README.md for model cards\n    repo_id=\"Wolverine001/bert_finetuned_senti\",\n    repo_type=\"model\",\n)\n\nprint(\"Model card updated! Check it at: https://huggingface.co/Wolverine001/bert_finetuned_senti\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:34:37.664859Z","iopub.execute_input":"2025-01-31T05:34:37.665152Z","iopub.status.idle":"2025-01-31T05:34:38.264665Z","shell.execute_reply.started":"2025-01-31T05:34:37.665124Z","shell.execute_reply":"2025-01-31T05:34:38.263810Z"}},"outputs":[{"name":"stdout","text":"Model card updated! Check it at: https://huggingface.co/Wolverine001/bert_finetuned_senti\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}